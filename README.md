# Text Summarizer
This is a text summarizer that:
- Scrapes Newsweek articles
- Generates extracted summaries using word frequency using [nltk](https://www.nltk.org/)'s word and sentence tokenizers
- Generates abstracted summaries using [PEGASUS](https://blog.research.google/2020/06/pegasus-state-of-art-model-for.html) Natural Language Processing model
- Displays statistics such as [ROUGE scores](https://en.wikipedia.org/wiki/ROUGE_(metric)) that quantify the accuracy of analysis, using tools such as NumPy, Pyplot, SciPy
---
This text summarizer consists of the following components:
1. Web Scraper
- Sends GET requests to the first 50 pages of Newsweek's site
- Uses BeautifulSoup library to obtain and deconstruct the obtained HTML
- Saves category, URL of article, title, summary, and full text of the article into a pandas data frame, and converts it into a .csv format for ease of access and to limit requests
---
2. Extracted Summary Generator
- Reads the .csv file produced by the web scraper and loads it into a pandas data frame
- Uses the punkt library in nltk to tokenize full texts into their words
- Punctuation is also removed for ease of analysis
- Obtains frequency of each word in the full text of each article
- Obtains top two sentences with the highest weights in each article, concatenating them to form the extracted summary for that article
- Extracted summary is updated into the data frame and converted into a .csv file, similarly to in the web scraper
---
3. Abstracted Summary Generator
- The .csv file from the extracted summary generator is loaded into a pandas data frame
- PyPlot was used to obtain histogram of summary length as a reference to set the max_length argument of the abstracted summaries generated by PEGASUS, and a maximum length of 100 was chosen as it was representative of our data
- PEGASUS Natural Language Processing tool was used to generate summaries for all the articles based on their full text (took around 6-8 hours)
- Data frame was updated with abstracted summaries and saved to .csv format for use in the summary analysis tool
---
4. Summary Analysis Tool
- The .csv file generated by the abstracted summary generator was loaded into a pandas data frame
- ROUGE scores were obtained for each of the summaries, with extracted summaries being compared to summaries and abstracted summaries being compared to summaries (ROUGE-1, ROUGE-2, and ROUGE-L were used in our case)
- Histograms were plotted using PyPlot in order to visualise the difference in distribution between the two scores
- Mann-Whitney U tests of difference were conducted between pairs of ROUGE-1, ROUGE-2 and ROUGE-L scores in order to determine if the two distributions differ significantly (at the 5% level of significance, we rejected the null hypothesis that the distributions were the same.)


